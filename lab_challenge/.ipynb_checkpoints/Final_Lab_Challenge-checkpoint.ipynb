{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IvVq-VIoPsDs"
   },
   "source": [
    "# Developing an AI application\n",
    "\n",
    "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
    "\n",
    "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
    "\n",
    "<img src='https://i.imgur.com/6n64KAw.png' width=500px>\n",
    "\n",
    "The project is broken down into multiple steps:\n",
    "\n",
    "* Load and preprocess the image dataset\n",
    "* Train the image classifier on your dataset\n",
    "* Use the trained classifier to predict image content\n",
    "\n",
    "We'll lead you through each part which you'll implement in Python.\n",
    "\n",
    "When you've completed this project, you'll have an application that can be trained on any set of labeled images. Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
    "\n",
    "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFKYE_43z9po"
   },
   "source": [
    "## Install PyTorch (setup for Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H9j1Df2quRrX"
   },
   "outputs": [],
   "source": [
    "# http://pytorch.org/\n",
    "from os.path import exists\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L1fGqdcBueWG"
   },
   "source": [
    "### Mount your Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VhrmH92ztR5G",
    "outputId": "01e4c931-8a36-4054-f0a7-5b631899f173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "un0rKns_zyuy"
   },
   "source": [
    "## Download the dataset (code setup for Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBmdmSuAvA6X"
   },
   "outputs": [],
   "source": [
    "#!wget \"https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\" -P \"drive/My Drive/PyTorch Challenge/\"\n",
    "#!unzip \"drive/My Drive/PyTorch Challenge/flower_data.zip\" -d \"drive/My Drive/PyTorch Challenge/Side Project/Flower_dataset/\"\n",
    "#!wget \"https://github.com/udacity/pytorch_challenge/blob/master/cat_to_name.json\" -P \"drive/My Drive/PyTorch Challenge/cat_to_name.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rpqNh3qfSybV"
   },
   "source": [
    "## Import the test environment \n",
    "### The functions below were used for calculating the accuracy with a function from built by the community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "OuAclTBSSv_m",
    "outputId": "b801f76d-b379-45e0-d368-718123fdb536"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'deep-learning-flower-identifier' already exists and is not an empty directory.\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.18.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2018.11.29)\n",
      "Requirement already satisfied: airtable in /usr/local/lib/python3.6/dist-packages (0.3.1)\n",
      "Requirement already satisfied: requests>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from airtable) (2.18.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.3->airtable) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.3->airtable) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.3->airtable) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.5.3->airtable) (1.22)\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/GabrielePicco/deep-learning-flower-identifier\n",
    "!pip install requests\n",
    "!pip install airtable\n",
    "import sys\n",
    "sys.path.insert(0, 'deep-learning-flower-identifier')\n",
    "from test_model_pytorch_facebook_challenge import publish_evaluated_model, calc_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rXpK2VM5k_0y"
   },
   "source": [
    "## Import (for Google Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "colab_type": "code",
    "id": "7EzSAxFSk0wK",
    "outputId": "e8d2e822-1d9e-42e8-9e84-6f264442f6d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling Pillow-5.4.1:\n",
      "  Successfully uninstalled Pillow-5.4.1\n",
      "Collecting Pillow==5.3.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.0MB 14.4MB/s \n",
      "\u001b[?25hInstalling collected packages: Pillow\n",
      "Successfully installed Pillow-5.3.0\n",
      "4.0.0\n"
     ]
    }
   ],
   "source": [
    "# we need pillow version of 5.3.0\n",
    "# we will uninstall the older version first\n",
    "!pip uninstall -y Pillow\n",
    "# install the new one\n",
    "!pip install Pillow==5.3.0\n",
    "# import the new one\n",
    "import PIL\n",
    "print(PIL.PILLOW_VERSION)\n",
    "# this should print 5.3.0. If it doesn't, then restart your runtime:\n",
    "# Menu > Runtime > Restart Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "CXFANeSHPsDu",
    "outputId": "bacd75cb-b0d2-4232-c29c-3b922ff121da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5bfb031950>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!pip install --no-cache-dir -I pillow\n",
    "# Imports here\n",
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "from google.colab import files\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vu0jssymPsDy"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). You can [download the data here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip). The dataset is split into two parts, training and validation. For the training, you'll want to apply transformations such as random scaling, cropping, and flipping. This will help the network generalize leading to better performance. If you use a pre-trained network, you'll also need to make sure the input data is resized to 224x224 pixels as required by the networks.\n",
    "\n",
    "The validation set is used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
    "\n",
    "The pre-trained networks available from `torchvision` were trained on the ImageNet dataset where each color channel was normalized separately. For both sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "99LuKlIPPsDz"
   },
   "outputs": [],
   "source": [
    "data_dir = 'drive/My Drive/PyTorch Challenge/Flower_dataset/flower_data/'\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "\n",
    "dirs = {'train': train_dir, \n",
    "        'valid': valid_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hO163BalPsD1"
   },
   "outputs": [],
   "source": [
    "size = 224\n",
    "data_transforms = data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(25),\n",
    "        transforms.RandomResizedCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(size + 32),\n",
    "        transforms.CenterCrop(size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "} \n",
    "\n",
    "image_datasets = {x: datasets.ImageFolder(dirs[x],   transform=data_transforms[x]) for x in ['train', 'valid']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=16, shuffle=True) for x in ['train', 'valid']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) \n",
    "                              for x in ['train', 'valid']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B3BD6gY9PsD4"
   },
   "source": [
    "### Label mapping\n",
    "\n",
    "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "itP3TwrqPsD5"
   },
   "outputs": [],
   "source": [
    "with open('drive/My Drive/PyTorch Challenge/cat_to_name.json', 'r') as f:\n",
    "    cat_to_name = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GtO1e5FPsD8"
   },
   "source": [
    "# Building and training the classifier\n",
    "\n",
    "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
    "\n",
    "We're going to leave this part up to you. If you want to talk through it with someone, chat with your fellow students! You can also ask questions on the forums or join the instructors in office hours.\n",
    "\n",
    "Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
    "\n",
    "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
    "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
    "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
    "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
    "\n",
    "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
    "\n",
    "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "qonDUhPZPsD9",
    "outputId": "816dd4c0-c469-408b-81b8-c6a3445765f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "#Load pretrained model    \n",
    "model = models.densenet161(pretrained=True)\n",
    "\n",
    "#freeze parameters so that we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ep1RdGifg3Mw"
   },
   "outputs": [],
   "source": [
    "#Uncomment if you want to print model architecture\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V_GShFGfxqZW"
   },
   "outputs": [],
   "source": [
    "# Adjust number of classes\n",
    "model.classifier = nn.Linear(2208, 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ePL_EUbPsEG"
   },
   "outputs": [],
   "source": [
    "def train_model(model, criteria, optimizer, scheduler, num_epochs=25, device='cuda'):\n",
    "    model.to(device)\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criteria(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'valid' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6_OsfVQPsEJ"
   },
   "outputs": [],
   "source": [
    "# Criteria NLLLoss which is recommended with Softmax final layer\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.006, momentum=0.9, nesterov=True)\n",
    "# Decay LR by a factor of 0.1 every 4 epochs\n",
    "sched = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "# Number of epochs\n",
    "eps=14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1339
    },
    "colab_type": "code",
    "id": "8q5ZhsXCPsEL",
    "outputId": "90a4ece8-ef49-4ba2-8883-e9bcae007635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/13\n",
      "----------\n",
      "train Loss: 2.1059 Acc: 0.5726\n",
      "valid Loss: 0.6228 Acc: 0.8741\n",
      "\n",
      "Epoch 1/13\n",
      "----------\n",
      "train Loss: 0.7747 Acc: 0.8410\n",
      "valid Loss: 0.3330 Acc: 0.9328\n",
      "\n",
      "Epoch 2/13\n",
      "----------\n",
      "train Loss: 0.5531 Acc: 0.8863\n",
      "valid Loss: 0.2666 Acc: 0.9413\n",
      "\n",
      "Epoch 3/13\n",
      "----------\n",
      "train Loss: 0.4573 Acc: 0.9009\n",
      "valid Loss: 0.2428 Acc: 0.9425\n",
      "\n",
      "Epoch 4/13\n",
      "----------\n",
      "train Loss: 0.4037 Acc: 0.9144\n",
      "valid Loss: 0.2097 Acc: 0.9511\n",
      "\n",
      "Epoch 5/13\n",
      "----------\n",
      "train Loss: 0.3633 Acc: 0.9171\n",
      "valid Loss: 0.1910 Acc: 0.9548\n",
      "\n",
      "Epoch 6/13\n",
      "----------\n",
      "train Loss: 0.3492 Acc: 0.9176\n",
      "valid Loss: 0.1984 Acc: 0.9548\n",
      "\n",
      "Epoch 7/13\n",
      "----------\n",
      "train Loss: 0.2864 Acc: 0.9350\n",
      "valid Loss: 0.1813 Acc: 0.9560\n",
      "\n",
      "Epoch 8/13\n",
      "----------\n",
      "train Loss: 0.2899 Acc: 0.9357\n",
      "valid Loss: 0.1691 Acc: 0.9584\n",
      "\n",
      "Epoch 9/13\n",
      "----------\n",
      "train Loss: 0.2823 Acc: 0.9396\n",
      "valid Loss: 0.1646 Acc: 0.9621\n",
      "\n",
      "Epoch 10/13\n",
      "----------\n",
      "train Loss: 0.2810 Acc: 0.9394\n",
      "valid Loss: 0.1745 Acc: 0.9560\n",
      "\n",
      "Epoch 11/13\n",
      "----------\n",
      "train Loss: 0.2771 Acc: 0.9417\n",
      "valid Loss: 0.1695 Acc: 0.9597\n",
      "\n",
      "Epoch 12/13\n",
      "----------\n",
      "train Loss: 0.2765 Acc: 0.9393\n",
      "valid Loss: 0.1699 Acc: 0.9621\n",
      "\n",
      "Epoch 13/13\n",
      "----------\n",
      "train Loss: 0.2583 Acc: 0.9451\n",
      "valid Loss: 0.1604 Acc: 0.9597\n",
      "\n",
      "Training complete in 127m 25s\n",
      "Best val Acc: 0.962103\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_ft = train_model(model, criteria, optimizer, sched, eps, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b8VnBpJxPsEP"
   },
   "source": [
    "## Save the checkpoint\n",
    "\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "4Gh_LSsy07A_",
    "outputId": "b3c79c06-3830-4e8a-87c1-1a5a756abb9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26,697,318 total parameters.\n",
      "225,318 training parameters.\n"
     ]
    }
   ],
   "source": [
    "# Find total parameters and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f'{total_params:,} total parameters.')\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'{total_trainable_params:,} training parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNHeDKgGPsEQ"
   },
   "outputs": [],
   "source": [
    "model_file_name = 'classifier_densenet161.pth'\n",
    "path = F\"drive/My Drive/PyTorch Challenge/{model_file_name}\" \n",
    "model.class_to_idx = image_datasets['train'].class_to_idx\n",
    "model.cpu()\n",
    "torch.save({'arch': 'densenet161',\n",
    "            'state_dict': model.state_dict(), \n",
    "            'class_to_idx': model.class_to_idx,\n",
    "            'optimizer_state_dict': optimizer.state_dict,\n",
    "            'criterion':criteria},\n",
    "             path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jmUhvmegPsEW"
   },
   "source": [
    "## Loading the checkpoint\n",
    "\n",
    "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W62JW_oRPsEW"
   },
   "outputs": [],
   "source": [
    "def load_model(checkpoint_path):\n",
    "    chpt = torch.load(checkpoint_path)\n",
    "    pretrained_model = getattr(models, chpt['arch'])\n",
    "    if callable(pretrained_model):\n",
    "        model = pretrained_model(pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "    else:\n",
    "        print(\"Sorry base architecture not recognized\")\n",
    "    \n",
    "    model.class_to_idx = chpt['class_to_idx']\n",
    "    \n",
    "    # Create the classifier\n",
    "    model.classifier = nn.Linear(2208, 102)\n",
    "    \n",
    "    model.load_state_dict(chpt['state_dict'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 588
    },
    "colab_type": "code",
    "id": "GcHUjCibPsEZ",
    "outputId": "f0563402-6d89-408a-c23a-44a4d8720374"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.90625\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.944444477558136\n",
      "Mean accuracy: 0.9642094373703003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96420944"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_model('drive/My Drive/PyTorch Challenge/classifier_densenet161.pth')\n",
    "calc_accuracy(model, input_image_size=224, testset_path=valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eihTdAizaadw"
   },
   "source": [
    "### Retrain only specific layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "colab_type": "code",
    "id": "fCrAE-0t5iyX",
    "outputId": "391b86a3-c308-4f1f-9f97-a6ecbdf4fba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv0 is frozen\n",
      "norm0 is frozen\n",
      "relu0 is frozen\n",
      "pool0 is frozen\n",
      "denseblock1 is frozen\n",
      "transition1 is frozen\n",
      "denseblock2 is frozen\n",
      "transition2 is frozen\n",
      "denseblock3 is frozen\n",
      "transition3 is frozen\n",
      "denseblock4 is unfrozen\n",
      "norm5 is unfrozen\n"
     ]
    }
   ],
   "source": [
    "# This is for DenseNet architecture, you need to adjust the method for each architecture\n",
    "for name in model.children():\n",
    "  for child, config in name.named_children():\n",
    "    if child in ['denseblock4', 'norm5']:\n",
    "      print(str(child) + ' is unfrozen')\n",
    "      for param in config.parameters():\n",
    "          param.requires_grad = True\n",
    "    else:\n",
    "      print(str(child) + ' is frozen')\n",
    "      for param in config.parameters():\n",
    "          param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pBj4OPEFdcRz"
   },
   "outputs": [],
   "source": [
    "#settings to train using different optimizer\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "#adjust optimizer \n",
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=0.00006, momentum=0.9, nesterov=True)\n",
    "# Use scheduler\n",
    "sched = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# Number of epochs\n",
    "eps=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1156
    },
    "colab_type": "code",
    "id": "2Bp-jNQ1dozX",
    "outputId": "6b6a14e5-6352-40df-80f5-92e80d675e28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/11\n",
      "----------\n",
      "train Loss: 0.1542 Acc: 0.9644\n",
      "valid Loss: 0.0872 Acc: 0.9817\n",
      "\n",
      "Epoch 1/11\n",
      "----------\n",
      "train Loss: 0.1539 Acc: 0.9621\n",
      "valid Loss: 0.0892 Acc: 0.9768\n",
      "\n",
      "Epoch 2/11\n",
      "----------\n",
      "train Loss: 0.1507 Acc: 0.9669\n",
      "valid Loss: 0.0864 Acc: 0.9804\n",
      "\n",
      "Epoch 3/11\n",
      "----------\n",
      "train Loss: 0.1377 Acc: 0.9687\n",
      "valid Loss: 0.0889 Acc: 0.9817\n",
      "\n",
      "Epoch 4/11\n",
      "----------\n",
      "train Loss: 0.1537 Acc: 0.9640\n",
      "valid Loss: 0.0914 Acc: 0.9804\n",
      "\n",
      "Epoch 5/11\n",
      "----------\n",
      "train Loss: 0.1379 Acc: 0.9681\n",
      "valid Loss: 0.0864 Acc: 0.9804\n",
      "\n",
      "Epoch 6/11\n",
      "----------\n",
      "train Loss: 0.1671 Acc: 0.9615\n",
      "valid Loss: 0.0899 Acc: 0.9792\n",
      "\n",
      "Epoch 7/11\n",
      "----------\n",
      "train Loss: 0.1487 Acc: 0.9643\n",
      "valid Loss: 0.0874 Acc: 0.9817\n",
      "\n",
      "Epoch 8/11\n",
      "----------\n",
      "train Loss: 0.1529 Acc: 0.9663\n",
      "valid Loss: 0.0872 Acc: 0.9817\n",
      "\n",
      "Epoch 9/11\n",
      "----------\n",
      "train Loss: 0.1488 Acc: 0.9663\n",
      "valid Loss: 0.0890 Acc: 0.9792\n",
      "\n",
      "Epoch 10/11\n",
      "----------\n",
      "train Loss: 0.1483 Acc: 0.9672\n",
      "valid Loss: 0.0893 Acc: 0.9804\n",
      "\n",
      "Epoch 11/11\n",
      "----------\n",
      "train Loss: 0.1570 Acc: 0.9644\n",
      "valid Loss: 0.0834 Acc: 0.9780\n",
      "\n",
      "Training complete in 59m 43s\n",
      "Best val Acc: 0.981663\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_full = train_model(model, criteria, optimizer, sched, eps, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AiR3K2HldzfG"
   },
   "outputs": [],
   "source": [
    "#save model\n",
    "model_file_name = 'classifier_densenet161_2.pth'\n",
    "path = F\"drive/My Drive/PyTorch Challenge/{model_file_name}\" \n",
    "model.class_to_idx = image_datasets['train'].class_to_idx\n",
    "model.cpu()\n",
    "torch.save({'arch': 'densenet161',\n",
    "            'state_dict': model.state_dict(), \n",
    "            'class_to_idx': model.class_to_idx,\n",
    "            'optimizer_state_dict': optimizer.state_dict,\n",
    "            'criterion':criteria},\n",
    "             path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 531
    },
    "colab_type": "code",
    "id": "mqK4uzH7duTB",
    "outputId": "09905866-fc37-4c1a-bfc5-73a47ba2774c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.9375\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 0.96875\n",
      "Batch accuracy (Size 32): 1.0\n",
      "Mean accuracy: 0.9819711446762085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.98197114"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate accuracy\n",
    "calc_accuracy(model, input_image_size=224, testset_path=valid_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0I7oB1aMcPv9"
   },
   "source": [
    "## Publish the result on the Airtable shared leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NHdX0lizcUZd"
   },
   "outputs": [],
   "source": [
    "#publish_evaluated_model(model, input_image_size=224,  username=\"@Slack.Username\", model_name=\"VGG19\", optim=\"Adam\", criteria=\"NLLLoss\", scheduler=\"StepLR\", epoch=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Image Classifier Project.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
